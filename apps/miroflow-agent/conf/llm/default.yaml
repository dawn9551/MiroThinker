# conf/llm/default.yaml - Default LLM configuration
provider: "anthropic" # openai, anthropic, qwen
model_name: "claude-3-7-sonnet-20250219"
async_client: false
temperature: 0.3
top_p: 1.0
min_p: 0.0
top_k: -1
max_tokens: 4096
max_context_length: 65536
api_key: "sk-3IPSAHXb0F66D6da04E8T3BlBkFJ72267f9FeF0e4cE58002"
base_url: https://c-z0-api-01.hash070.com
repetition_penalty: 1.0
